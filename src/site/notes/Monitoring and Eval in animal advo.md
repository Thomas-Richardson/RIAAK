---
{"dg-publish":true,"permalink":"/monitoring-and-eval-in-animal-advo/","tags":[null,null,null,null],"created":"2025-10-23T17:42:41.636+01:00","updated":"2025-10-30T23:44:52.978+00:00"}
---




[According to the Mission Motor](https://drive.google.com/file/d/1outCnQHRVHgSMgCEkQWGSHJNNzMq2E_l/view):
- high interest in and perceived need for MEL
- probably greater need for modularised MEL tools rather than building complete systems
- Small data so more qual than quan
- They stopped doing a cohort model because no size fits all

Experts indicate spending between 3 and 20% of a program budget on MEL is deemed adequate for ensuring accountability, assessing effectiveness, and providing opportunities for learning and continuous improvement.
## Why MEL fails
- MEL being complex and overwhelming
- using the wrong tools
- lack of training
- some types of interventions such as lobbying, are hard to measure
- itâ€™s often difficult to quantify the impact
## My thoughts
- Do they want to target high funding, large, but potentially ineffective orgs, because they are the highest leverage for improving MEL?
- Can tiny stats tools improve things as well as qual?
- Can Mission Motor collect org wide data that they share with all orgs to get around small data problem?
-

# AI suggested related notes

These notes appear semantically similar based on Smart Connections embeddings:

- [[R&D in animal advo\|R&D in animal advo]] (similarity: 60.8%)
- [[Bryant Confidential/Notes on animal advo and science symposium, 2023\|Notes on animal advo and science symposium, 2023]] (similarity: 57.0%)
- [[Social listening for animal orgs - things we've learned\|Social listening for animal orgs - things we've learned]] (similarity: 56.0%)
